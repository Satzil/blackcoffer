# -*- coding: utf-8 -*-
"""blackcoffer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E2ePSQCN38SJlJHuC6SMVrEe-0IviU7g
"""



import pandas as pd
from selenium import webdriver
import os
from selenium.webdriver.common.by import By

options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=options)

def extract_and_save_data(url, output_file,class_name1,class_name):

    driver.get(url)

    # Extract text and title
    #body_element = driver.find_element("xpath", "//body")



    #content_element1=driver.find_element(By.CLASS_NAME,class_name1)

    content_element1 = driver.find_element('css selector', f'h1.{class_name1}')
    element_text1=content_element1.text


    content_element = driver.find_element(By.CLASS_NAME,class_name)
    element_text = content_element.text


    # Specify the directory where you want to save the files
    output_directory = "output_files"

    # Create the output directory if it doesn't exist
    os.makedirs(output_directory, exist_ok=True)

    # Combine the directory and file name to create the full path
    full_output_path = os.path.join(output_directory, output_file)

    # Save the extracted data to a text file
    with open(full_output_path, "w", encoding="utf-8") as file:

        file.write(f"{element_text1}\n")
        file.write(f"{element_text}\n")
        print(full_output_path)



# Read URLs from Excel file using pandas
excel_file = "/content/details/Input.xlsx"
  # Replace with the path to your Excel file
df = pd.read_excel(excel_file)

# # Iterate through each row in the DataFrame and extract data
for index, row in df.iterrows():
      url = row["URL"]
      url_id = row["URL_ID"]
      #output_file = f"output_{index + 1}.txt"
      output_file = f"{url_id}.txt" # You can customize the output file names if needed
      try:
        extract_and_save_data(url, output_file,'entry-title','td-post-content')
      except Exception as e:
        try:
          extract_and_save_data(url, output_file,'tdb-title-text','tdb-block-inner')
        except Exception as e:
          print('No content')

          with open('output_files/'+output_file, "w", encoding="utf-8") as file:
            file.write(f"")


driver.quit()



import pandas as pd
import os
import nltk
import string
from nltk.corpus import stopwords, cmudict
from nltk.tokenize import word_tokenize, sent_tokenize, LineTokenizer
import syllables
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('cmudict')

def get_words_from_file(file_path):
    file = open(file_path, 'r', encoding='latin-1')
    words = file.read().splitlines()
    words = [s.split('|')[0].strip().lower() for s in words]
    return words.copy()

def get_words_from_dir(folder_path):
    final_words = []
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)

        final_words += get_words_from_file(file_path)
    return final_words

def extract_text_from_file(file_path):
    file = open(file_path, 'r', encoding='latin-1')
    text = file.read()
    return text.lower()

def get_scores(text):
    words = word_tokenize(text)
    sentences = nltk.sent_tokenize(text)
    translator = str.maketrans("", "", string.punctuation)
    filtered_words = [word.translate(translator) for word in words if word.isalnum()]
    cleaned_words = [word for word in filtered_words if word not in stop_words]

    pronouncing_dict = cmudict.dict()
    complex_words = [word for word in filtered_words if syllables.estimate(word) > 2]
    total_syllable_count = sum([syllables.estimate(word) for word in filtered_words])
    personal_pronouns = set(['i','we','my','ours','us'])
    total_number_of_characters = sum([len(word) for word in filtered_words])

    positive_score = 0
    negative_score = 0
    for word in cleaned_words:
        if word in positive_words:
            positive_score += 1
        if word in negative_words:
            negative_score += 1
    polarity_score = (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)
    subjective_score = (positive_score + negative_score) / (len(cleaned_words) +0.000001)
    average_sentence_length = len(filtered_words)/len(sentences) if len(sentences) > 0 else 0
    percentage_of_complex_words = len(complex_words)/len(filtered_words) if len(filtered_words) > 0 else 0
    fog_index = 0.4 * (average_sentence_length + percentage_of_complex_words)
    average_number_of_words_per_sentence = len(filtered_words)/len(sentences) if len(sentences) > 0 else 0
    complex_word_count = len(complex_words)
    word_count = len(cleaned_words)
    syllable_count_per_word = total_syllable_count/len(filtered_words) if len(filtered_words) > 0 else 0
    personal_pronouns_count = len([word for word in filtered_words if word in personal_pronouns])
    average_word_length = total_number_of_characters/len(filtered_words) if len(filtered_words) > 0 else 0
    return {
        'positive_score':positive_score,
        'negative_score':negative_score,
        'polarity_score':polarity_score,
        'subjective_score':subjective_score,
        'average_sentence_length':average_sentence_length,
        'percentage_of_complex_words':percentage_of_complex_words,
        'fog_index':fog_index,
        'average_number_of_words_per_sentence':average_number_of_words_per_sentence,
        'complex_word_count':complex_word_count,
        'word_count':word_count,
        'syllable_count_per_word':syllable_count_per_word,
        'personal_pronouns_count':personal_pronouns_count,
        'average_word_length':average_word_length
    }

english_stopwords = stopwords.words('english')
stop_words = set(get_words_from_dir('20211030 Test Assignment/StopWords')) | set(english_stopwords)
positive_words = set(get_words_from_file('20211030 Test Assignment/MasterDictionary/positive-words.txt'))- stop_words
negative_words = set(get_words_from_file('20211030 Test Assignment/MasterDictionary/negative-words.txt'))- stop_words
folder_path = 'output_files'
all_scores = {}
for filename in os.listdir(folder_path):
    file_path = os.path.join(folder_path, filename)
    text = extract_text_from_file(file_path)
    scores = get_scores(text)
    all_scores[filename] = scores
    print(filename)

import pandas as pd

def apply_scores(row):
  scores = ['positive_score','negative_score','polarity_score','subjective_score','average_sentence_length',
                'percentage_of_complex_words','fog_index','average_number_of_words_per_sentence','complex_word_count',
                'word_count','syllable_count_per_word','personal_pronouns_count','average_word_length']
  for score in scores:
    row[score] = all_scores[row['URL_ID']+'.txt'][score]
  return row



df = pd.read_excel('20211030 Test Assignment/Input.xlsx')
df = df.apply(apply_scores,axis = 1)
df.to_excel('output.xlsx', index=False)

all_scores